# Development Log for CS4099 - Virutal Modular Synthesizer
## 24th Sept, 2022
Beginning devlog here, to keep track of design decisions made along the way.  So far:
- Using Rust + WASM to develop the audio engine, for mostly performance reasons, and I like Rust.  C++ is the normal choice for audio development, with mature package support, but the process of getting it to play nice with WASM seems like a PITA, and rust is pretty straightforward.  While the native JS implementations of the nodes I will be implementing are very fast, the nodes provided by the Web Audio API are fairly limitted.
- Using NextJS for the frontend, mostly because I'm comfortable with it.  Planning on just doing regular html elements for the nodes, and connecting them with generated SVG Bezier curves.  This is in opposition to doing a full canvas-based application.  Canvas based applications tend to be pretty laggy, in my experience.
- As far as influences goes, Glicol is a really interesting project, and does something pretty similar to this, with a powerful synthesis engine based in WASM.  The primary decision is that Glicol is aiming at building a DSP/Synthesis language, instead of a graphical tool.  The engine is open source, but from the looks of it the graph implementation isn't quite what I'm looking for, so I plan on rolling my own. There's also AudioNodes, which is a browser based modular synth similar to what I'm aiming for.  Unfortunately, the canvas based frontend is pretty laggy, and development seems fairly innactive.  In addition, it doesn't leverage WASM, one of the primary goals of this project.  Because of this, all of the audio processing gets done in Javascript.
- I'll be using the dasp crate for a lot of the audio processing basics.  However, the dasp_graph crate, which provides the audio graph implementation in dasp, is too limited for my implementation, so I have forked it in the audio_graph crate.  I will be adding the features I need there, as well as the node implementations I will need.  I got the idea for expanding upon dasp_graph from Glicol, although it takes it in a different direction.  The main change I'm making is to make it so instead of each node having arbitrary inputs and outputs, there will be many inputs and outputs with port numbers, on which each node can send and receive data.  One consequence of this is that all data will move at the sample rate.  If this leads to performance problems, it would be possible to make multiple kinds of connections, some which send full buffers, and others single values.
## 25th Sept, 2022
Been feeling a bit "in the hole" doing so much work on this.  Going to try and work at a more reasonable (and maintainable) pace.
- Continued refactoring the audio_graph fork.  Each `Node` has a function called `get_port` which is just a lookup using the port type and input name to the port number.  This will help keep magic port numbers out of the code, and hopefully will mean the port numbers only get used explicitly within each node's implementation.  The lookups should also be pretty fast.  I deleted the default `Signal` and `Sum` nodes, as I will be rewriting these from scratch anyways in some sort of `Oscillator` and `Mixer` nodes, respectively.  I'm fairly happy with how the audio_graph fork is coming together, I think it'll be successful at providing a clean interface for the more business logic-ey code of manipulating the nodes.  Of course, this is all as of yet untested, so we'll see how it goes :).  Tomorrow I'll do the impl for the subgraph node, which shouldn't be too bad but is non-trivial to refactor.  Subgraphs would be really nice, because modules could be encapsulated and shared around easily.
## 26th Sept, 2022
- Subgraph node implemented, was sort of a pain in the ass.  As it stands, it takes in a graph, which needs to have a single output node.  Then the user can create and map external input nodes to input nodes of the internal nodes of the subgraph.  For the output ports, the output ports from the internal output node are mirrored.
## 28th Sept, 2022
- Audio graph is working!
- Next step is writing an oscilloscope to make it easier to debug issues with audio modules.  A proof of concept was written in a code pen.  It uses analyzer, but we will just use the samples directly out of wasm.
## 30th Sept, 2022
- Made a crude oscilloscope to help with debugging.  Not my finest work but should do alright for now.
- Next step is to expand the oscillator module.   Would be good to get some sort of FM Synthesis test done ASAP.